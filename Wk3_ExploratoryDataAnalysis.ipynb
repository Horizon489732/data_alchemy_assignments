{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structure & Guidelines\n",
    "\n",
    "The most important thing to do is define your problem statement (with your partner). This will be your nexus and will help you choose the dataset. Ideally this is the problem that you work on for the rest of the project. Since this is a big decision, you can change the problem statement and the dataset in the next assignment but no changes after that.\n",
    "\n",
    "### Where to look for a dataset\n",
    "There are too many sources for me to name all of them. **Kaggle** is the most popular. To search you can just use google or **Google Dataset Search** specifically. A lot of universities have their datasets available, like the one I use in my example below, which can be a great resource too. \n",
    "\n",
    "\n",
    "### EDA Study\n",
    "Here are some mandatory material to help you get a basic understanding:\n",
    "- https://www.analyticsvidhya.com/blog/2022/07/step-by-step-exploratory-data-analysis-eda-using-python/\n",
    "- https://www.youtube.com/watch?v=9m4n2xVzk9o\n",
    "\n",
    "The sky is the limit with EDA, use this as a starting point and I expect you to go beyond. For instance I personally love this free book https://jakevdp.github.io/PythonDataScienceHandbook/ that dives deep into data science with python. <br>\n",
    "This book is entirely in jupyter notebooks for even more code examples: https://allendowney.github.io/ElementsOfDataScience/\n",
    "\n",
    "\n",
    "### Working with partners\n",
    "To reiterate, you will decide the problem statement and the dataset together with you partner(s). I encourage you to work on the assignments together, disucss analytical processes and insights. If you are more experienced/knowledgable than your partner, please take the lead and help them understand any difficult concepts. \n",
    "\n",
    "**The idea is to foster collaboration and get support on the path to self-suffciency.**<br>\n",
    "This means your assignment submissions, your final analyses and dashboard has to be completely your own. You should work on those independently. <br>\n",
    "For example, discussing a specific assignent task is okay but copying your partners answers is not. Attempt to understand from them and write what you know so when I give my feedback it is valuable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assignment Questions/Tasks\n",
    "\n",
    "1) Discuss & write down a problem statement\n",
    "2) Find a Dataset(s) that will help you solve your problem\n",
    "3) EDA Study: Go through the guides I link above and my example to get different perspective of how to approach EDA\n",
    "4) Start your EDA by emulating the steps I take below and start forming hypotheses about the dataset and getting insights\n",
    "5) Use 5 more visualizations or techniques of your choice that I dont use below\n",
    "6) Write down insights about the dataset and how it relates back to your problem!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "This is the same example from class. I have kept things basic and barebones here so this can serve as a springboard for your analyses. In each step I have added some questions you should ask to get insights into the dataset. The answers to these and other questions that you ask might be through more statistical analysis and visualizations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading & Quick Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your dataset here\n",
    "adult_income_dataset = fetch_ucirepo(id=2) #details here https://archive.ics.uci.edu/dataset/2/adult, click on the import in python button to check it out\n",
    "df = adult_income_dataset.data.original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to ponder: \n",
    "\n",
    "1. Does the data match your expectations or do you think you might need more information?\n",
    "2. Do the columns/features align with your problem statement?\n",
    "3. Any immediate signs of missing or corrupted data? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Shape & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape : (rows, columns)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display all column names\n",
    "print(\"\\nFeature Names:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to ponder: \n",
    "\n",
    "1. Is the data large enough for the analysis?\n",
    "2. Are there any duplicate columns, or columns with similar information or ones that need re-naming? (I renamed some columns in my dataset below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing \"-\" with \"_\"\n",
    "df.columns = df.columns.str.replace(\"-\",\"_\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get unique target values\n",
    "df['income'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Types & Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding the datatypes\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "print(\"\\nMissing Values Count:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to ponder: \n",
    "\n",
    "- Should we drop or impute missing values?\n",
    "- Could missing data be an insight in and of itself?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Summary Statistics & Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary Stats\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question to ponder\n",
    "- Did you expect outliers? \n",
    "- Which features have unusually high or low values? What do they tell us about the data?\n",
    "- Are there any suspicious patterns or extreme outliers?\n",
    "- Do we need to drop or transform these outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"capital_gain\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for visualization (Choosing the numerical features)\n",
    "num_features = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "\n",
    "# Create a 2x3 grid for visualization\n",
    "fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Iterate over features and plot\n",
    "for i, feature in enumerate(num_features):\n",
    "    row, col = divmod(i, 3)\n",
    "    sns.histplot(df[feature], kde=True, bins=30, ax=ax[row, col])\n",
    "    ax[row, col].set_title(f'Distribution of {feature}')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplots for numerical variables\n",
    "fig, ax = plt.subplots(3, 2, figsize=(18, 15))\n",
    "\n",
    "for i, feature in enumerate(num_features):\n",
    "    row, col = divmod(i, 2)\n",
    "    sns.boxplot(y=df[feature], ax=ax[row, col])\n",
    "    ax[row, col].set_title(f'Boxplot of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create violin plots for numerical variables\n",
    "fig, ax = plt.subplots(3, 2, figsize=(18, 15))\n",
    "\n",
    "for i, feature in enumerate(num_features):\n",
    "    row, col = divmod(i, 2)\n",
    "    sns.violinplot(y=df[feature], ax=ax[row, col])\n",
    "    ax[row, col].set_title(f'Violin Plot of {feature}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical features for visualization\n",
    "cat_features = ['workclass', 'education', 'marital_status', 'occupation', 'relationship', 'race']\n",
    "\n",
    "# Create a 2x3 grid for visualization\n",
    "fig, ax = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Iterate over categorical features and plot\n",
    "for i, feature in enumerate(cat_features):\n",
    "    row, col = divmod(i, 3)\n",
    "    sns.countplot(data=df, x=feature, order=df[feature].value_counts().index, ax=ax[row, col])\n",
    "    ax[row, col].set_title(f'Distribution of {feature}')\n",
    "    ax[row, col].tick_params(axis='x', rotation=40)  # Rotate x-axis labels for better readability\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to ponder:\n",
    "\n",
    "- Are the numerical features skewed or roughly normal?\n",
    "- Which categories dominate in each categorical feature? What does that tell you about each feature? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for numerical vs. numerical\n",
    "sns.scatterplot(data=df, x='age', y='income')\n",
    "plt.title(\"age vs. income\")\n",
    "plt.show()\n",
    "\n",
    "# Grouped bar plot for categorical vs. categorical\n",
    "sns.countplot(data=df, x='education', hue='marital_status')\n",
    "plt.title(\"Categorical Relationship\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Box plot for numerical vs. categorical\n",
    "sns.boxplot(data=df, x='education', y='age')\n",
    "plt.title(\"Boxplot: age by education\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to ponder\n",
    "\n",
    "- Which numerical features are correlated?\n",
    "- Do certain categories strongly associate with higher or lower numerical values?\n",
    "- Any visible clusters or patterns in scatter plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(df.select_dtypes(include=['number']).corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions to ponder\n",
    "\n",
    "- Which features show strong correlation?\n",
    "- Should we remove or combine highly correlated features?\n",
    "- Are there surprising correlations that warrant deeper investigation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Next Steps\n",
    "\n",
    "- Which features appear most important for the problem?\n",
    "- What data cleaning or transformation steps remain?\n",
    "- How will these insights guide the next phase (modeling, reporting, or business decisions)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- Another amazing free book I have used : https://greenteapress.com/thinkstats/thinkstats.pdf\n",
    "- https://towardsdatascience.com/data-science-101-life-cycle-of-a-data-science-project-86cbc4a2f7f0/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
